{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05335cd9-b5bf-40f4-8498-822722792b12",
   "metadata": {},
   "source": [
    "<img src=\"./images/build_ai_job_application_helper_app.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8014e54-3b0b-49aa-9d50-69fd30b23b6e",
   "metadata": {},
   "source": [
    "# Welcome to the _AI job application helper app_!\n",
    "\n",
    "This Jupyter Notebook is from [Tampa Bay Artificial Intelligence Meetup’s](https://www.meetup.com/tampa-artificial-intelligence-meetup/) exercise from [our session on Monday, March 17, 2025](https://www.meetup.com/tampa-artificial-intelligence-meetup/events/306353685/?eventOrigin=group_upcoming_events), which took place at [Embarc Collective](https://embarccollective.com/) in [Tampa](https://en.wikipedia.org/wiki/Tampa,_Florida). It was organized by [Joey de Villa](https://www.linkedin.com/in/joeydevilla/) and [Anitra Pavka](https://www.linkedin.com/in/anitrapavka/).\n",
    "\n",
    "In that session, we demonstrated how to build an application to help people with the job search process. Feel free to use it in your job search, and feel free to modify it to suit your job search needs!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c3ae463-b089-43db-8144-b56311422132",
   "metadata": {},
   "source": [
    "## The job-seeker’s challenge\n",
    "\n",
    "<img src=\"./images/you_know_what_this_is_like.png\" width=\"600\" />\n",
    "\n",
    "According to the Silicon Valley-based career guidance service Pathrise, [job seekers who sent 20+ job applications every week got more interviews and landed a job sooner](https://www.pathrise.com/guides/how-long-does-it-take-to-find-a-job/).\n",
    "\n",
    "That’s a lot of work, especially since the general advice is to [customize your résumé for every job application](https://resume.io/blog/customize-resume-for-each-application) and to [write a custom cover letter for each job application](https://novoresume.com/career-blog/do-i-need-a-cover-letter) as well.\n",
    "\n",
    "Now imagine going through that process at least 20 times a week.\n",
    "\n",
    "This application sets out to solve that problem. It uses an AI — more specifically, a large language model (LLM) — to perform the repetitive task of creating résumés and cover letters that are customized for each job application you fill out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387f979-58eb-416c-bed3-3516f1f839c1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Set up an OpenAI secret key\n",
    "Because getting everyone in this meetup to set up and OpenAI API account and an API key would probably take all the allotted time, we’re going to keep things simple. **In this meetup, you’ll use Joey’s OpenAI account and an API key that will be active only during the meetup.** In order to run this application after the meetup, you’ll need the following:\n",
    "\n",
    "- **An OpenAI account.** You can sign up for one at the [OpenAI Platform page](https://platform.openai.com/).\n",
    "- **A secret key.** Log into OpenAI and visit the [API keys page](https://platform.openai.com/api-keys), and create a new secret key by clicking the **Create New Secret Key** button.\n",
    "- **Some money in your OpenAI credit balance.** As it says on the [Billing page](https://platform.openai.com/settings/organization/billing/overview), “When your credit balance reaches $0, your API requests will stop working.” Fortunately, one or two US dollars should be enough to cover running this application many, many times.\n",
    "\n",
    "Once you have created a secret key, copy that key. Create a file named `.env` in the same directory as this notebook and enter the following into that file:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY = replace_this_with_your_secret_key\n",
    "```\n",
    "\n",
    "> Filenames that begin with `.` (period) characters are system files, and for your safety, macOS hides them. You can make them visible by using the ⌘-shift-. keyboard shortcut (that is, hold down command, shift, and the `.` keys at the same time) when looking at a Finder window or when opening files.\n",
    "\n",
    "Replace `replace_this_with_your_secret_key` with your secret key and save the file. By storing the API key in a `.env` file (and making sure that the .env is _not_ added to source control), you avoid “hard-coding” the API key into your application, which makes it more likely that someone unauthorized will discover it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4526797",
   "metadata": {},
   "source": [
    "### Install the packages used by this application\n",
    "There’s no need to reinvent the wheel when we Python has a large collection of packages to take care of things so we don’t have to code them ourselves. Let’s install the following packages:\n",
    "\n",
    "- `dotenv`: Provides functions for reading `.env` files to create environment variables. We’ll use this to get the API keys so that the application can talk to LLMs.\n",
    "- `markdown-pdf`: Converts Markdown documents into PDF documents. We’ll use this to generate the final copy of the customized résumé.\n",
    "- `openai`: Provides functionality for communicating with OpenAI’s AI models.\n",
    "- `pyperclip`: Gives our application access to the clipboard.\n",
    "\n",
    "The command below installs these packages, which are listed in the file `requirements.txt`. If it doesn’t work, try replacing `pip` with `pip3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf961cd-9644-4443-bd6c-94e51bb27f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8cb733",
   "metadata": {},
   "source": [
    "### Import the necessary packages\n",
    "With all the packages installed, we can now import them, along with some standard Python packages, namely `os` and `sys`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0023daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pyperclip\n",
    "from dotenv import load_dotenv\n",
    "from markdown_pdf import MarkdownPdf, Section\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665cf27-9bad-44fd-b7b9-65f9f8596b0d",
   "metadata": {},
   "source": [
    "## Create functions for working with OpenAI\n",
    "\n",
    "### Create an OpenAI client object\n",
    "The first step in building an OpenAI-powered application is to create an instance of the OpenAI client class. We’ll call it `client`, and it will enable access to OpenAI’s various APIs, including the one we’ll use: GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7472d7e5-5d9e-45db-9cc8-5801e30c5374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When called without arguments, OpenAI will try to get\n",
    "# the API key from the OPENAI_API_KEY environment variable.\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581edcbc",
   "metadata": {},
   "source": [
    "### Create a completion function\n",
    "Once we’ve created an OpenAI client object, let’s use it to create a _completion_. In the context of an LLM, a completion is the text that the model generates in response to a given prompt. It's essentially the output that the AI produces to “complete” the input it has been given.\n",
    "\n",
    "In order to create a completion, we’ll use the `OpenAI` class’ `chat.completions.create()` method and provide it with the following information:\n",
    "\n",
    "- **Model:** For the purposes of the meetup, we’ll use the **GPT-4o mini** model, a smaller, faster model that costs less to run. After the meetup, and once you’re using your own OpenAI account, you can change this out for a more capable (but more expensive) model.\n",
    "- **Temperature:** A parameter that controls the randomness or predictability of the model's outputs. It's named after the temperature parameter in statistical physics, where higher temperatures lead to more disorder. It’s essentially a \"creativity dial\" that lets developers or users control how much the LLM sticks to the most likely responses versus exploring more varied possibilities. In most LLMs, this is a value between 0 and 2, and the default value is 1.\n",
    "- **Messages:** A list of messages that make up the exchange or “conversation” with the LLM. Each message is a dictionary with two keys:\n",
    "  - `role`: Defines the “speaker” of the message. It's essentially a label that identifies the source and purpose of each message in the exchange. It can be one of these three values:\n",
    "    - `\"system\"`: The initial instructions or context given to the model. Sets the overall behavior, personality, and constraints for the LLM. Establishes rules and guidelines for how the model should respond. Often includes information about the model's capabilities and limitations. Not directly visible to users in most interfaces.\n",
    "    - `\"user\"`: Represents the person interacting with the LLM. Provides queries, instructions, or content for the model to respond to. Drives the direction of the conversation.\n",
    "    - `\"assistant\"`: Represents the LLM's responses. Contains the generated completions from the model. Follows the guidelines established in the system role, and responds directly to user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a8ad8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_completion(\n",
    "    system_prompt,\n",
    "    user_prompt,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1.0\n",
    "):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f70cc",
   "metadata": {},
   "source": [
    "In our test completion, let’s ask what the fastest bird in the world is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abed8b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_completion = create_completion(\n",
    "    \"You are a helpful assistant\",\n",
    "    \"What’s the fastest bird in the world?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b57f53",
   "metadata": {},
   "source": [
    "Now that we have the completion, let’s see what it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e2a59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-Bgl43O3DdIFcQ4ioHQZLpUs1F22BJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The fastest bird in the world is the peregrine falcon. During its hunting stoop (high-speed dive), it can reach speeds of over 240 miles per hour (386 kilometers per hour). This makes it not only the fastest bird but also the fastest animal on the planet. When flying level, the fastest bird is the common swift, which can reach speeds of around 69 miles per hour (111 kilometers per hour).', role='assistant', function_call=None, tool_calls=None, refusal=None, annotations=[]))], created=1749530391, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_34a54ae93c', usage=CompletionUsage(completion_tokens=86, prompt_tokens=25, total_tokens=111, prompt_tokens_details={'cached_tokens': 0, 'audio_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}))\n"
     ]
    }
   ],
   "source": [
    "print(test_completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a11fa",
   "metadata": {},
   "source": [
    "The `create_completion()` function returns _a lot_ of information. Let’s update it so that instead of returning a `ChatCompletion` object, it returns just the info we _really_ care about: the answer.\n",
    "\n",
    "`ChatCompletion` objects contain a list called `choices`, which contain the answers generated by the LLM. Most of the time, there’s just one item in `choices`, so we’ll extract that item, `choice[0]`. `choice[0]` has a `message` property containing the answer, and the text of that answer is in the `message` property’s `content` property.\n",
    "\n",
    "Here’s an updated version of `create_completion()` that returns just the answer, and nothing else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0fadc16-4332-4cab-9748-80014a7ff455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_completion(\n",
    "    system_prompt,\n",
    "    user_prompt,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1.0\n",
    "):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6895d37",
   "metadata": {},
   "source": [
    "Let’s test this new version of `create_completion()`. It should now return the LLM’s answer, and nothing else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed4bdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fastest bird in the world is the peregrine falcon. When in a dive, known as a stoop, it can reach speeds of over 240 miles per hour (386 kilometers per hour). This incredible speed makes the peregrine falcon not only the fastest bird but also the fastest animal on the planet.\n"
     ]
    }
   ],
   "source": [
    "test_completion = create_completion(\n",
    "    \"You are a helpful assistant\",\n",
    "    \"What’s the fastest bird in the world?\",\n",
    ")\n",
    "print(test_completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad76338",
   "metadata": {},
   "source": [
    "Now that we have a function to communicate with the LLM, let’s build the rest of the program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2c6ed-41b7-410a-833a-575c1519390a",
   "metadata": {},
   "source": [
    "## Define the inputs\n",
    "\n",
    "We need to create three files that our app will use to generate resumes and cover letters.\n",
    "\n",
    "### Reference résumé\n",
    "In order to create résumés customized to fit job descriptions, the app needs a reference résumé. This reference résumé is simply your résumé in Markdown format, saved as a file named `reference_resume.md` in the `input` directory. For the meetup, we used my résumé for this file, which is included in this project’s repo.\n",
    "\n",
    "By providing your résumé in Markdown format, you can specify formatting such as headings, bold and italics, bullet points, and even hyperlinks. This will be useful later, when we convert the resulting customized résumé into a PDF or Microsoft Word file.\n",
    "\n",
    "### Job description\n",
    "Copy the job description for the job you want to generate a customized résumé for and save it into a file named `job_description.md`. Convert any formatting in the job description into Markdown — the formatting can provide the LLM with additional context that it might use when generating a customized résumé. I provided a sample version of `job_description.md` in this project’s repo, in the `input` directory.\n",
    "\n",
    "### System prompt\n",
    "To provide better résumés and cover letters, this app will use a system prompt that defines the general way in which the LLM should behave when generting them. It’s in the `system_prompt.md` file in the `input` directory.\n",
    "\n",
    "Think of a system prompt like this:\n",
    "\n",
    "1. **It's like a job description and behavioral guideline:** The system prompt tells the AI who it is, how it should behave, what tone to use, what it can and cannot discuss, and how to handle different types of questions.\n",
    "2. **It provides background knowledge:** The system prompt may include specific facts that the AI should know about itself or various topics.\n",
    "3. **It establishes boundaries:** The prompt defines what kinds of requests the AI should decline and how to politely redirect conversations when needed.\n",
    "4. **It shapes the AI's \"personality\":** Whether the AI comes across as formal, casual, detailed, concise, humorous, or serious is largely influenced by the system prompt.\n",
    "\n",
    "When you interact with an AI assistant, you're seeing the result of these behind-the-scenes instructions working together with the AI's training. The system prompt is invisible to users but shapes every response you receive.\n",
    "\n",
    "I’ve provided this prompt in a file named `system_prompt.md`. Take a look at it, and feel free to change it as you see fit.\n",
    "\n",
    "### Reading the files\n",
    "Let’s define `read_file()`, a function that returns the contents of a given text file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a656562-e03d-41d7-96d2-8044461ab137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    try:\n",
    "        with open(filename) as f:\n",
    "            print(f\"Reading {filename}...\")\n",
    "            return f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{filename} not found.\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\"Successfully read {filename}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e00f3",
   "metadata": {},
   "source": [
    "...and then use it to define the inputs for the app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113fa840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./input/reference_resume.md...\n",
      "Reading ./input/system_prompt.md...\n",
      "Reading ./input/job_description.md...\n"
     ]
    }
   ],
   "source": [
    "REFERENCE_RESUME = read_file(\"./input/reference_resume.md\")\n",
    "SYSTEM_PROMPT = read_file(\"./input/system_prompt.md\")\n",
    "JOB_DESCRIPTION = read_file(\"./input/job_description.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff406e",
   "metadata": {},
   "source": [
    "## Create functions to build the résumé\n",
    "\n",
    "### Create a function to define a user prompt for optimizing the user’s résumé\n",
    "The _user prompt_ is the input or question that the user sends to the LLM. Let’s define a function that takes the user’s résumé and a job description and returns a user prompt asking the LLM to create a version of the résumé optimized for the given job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "699172ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resume_prompt(reference_resume, job_description):\n",
    "    return f\"\"\"\n",
    "        I need you to optimize a résumé to better match a job description. The goal is to present the candidate's experience \n",
    "        in a way that shows they're an excellent fit for the position, while remaining truthful and professional.\n",
    "\n",
    "        Here's the original résumé in Markdown format...\n",
    "        --- BEGIN RESUME ---\n",
    "        {reference_resume}\n",
    "        --- END RESUME ---\n",
    "        \n",
    "        ...and here's the job description that the résumé should be tailored to:\n",
    "        --- BEGIN JOB DESCRIPTION ---\n",
    "        {job_description}\n",
    "        --- END JOB DESCRIPTION ---\n",
    "\n",
    "        Please analyze the job description, identify key requirements and skills, and modify the résumé to highlight \n",
    "        relevant experience and accomplishments that match these requirements.\n",
    "\n",
    "        In your response, please ensure the following:\n",
    "        1. Maintain the original formatting and structure of the résumé.\n",
    "        2. Do not invent any qualifications or experiences that are not present in the original résumé.\n",
    "        3. Focus on emphasizing relevant skills and experiences.\n",
    "        4. Use strong action verbs and quantify achievements where possible.\n",
    "        5. Ensure the résumé is clear, concise, and professional.\n",
    "        6. Maintain the Markdown formatting in your response.\n",
    "        7. Return ONLY the optimized résumé, without any explanations.\n",
    "\n",
    "        Return the optimized resume in Markdown format.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2269c7e-03e8-4559-ada9-c0b6ffe80de3",
   "metadata": {},
   "source": [
    "### Create a function to generate a customized resume\n",
    "\n",
    "This function will take the following inputs:\n",
    "\n",
    "1. Base résumé\n",
    "2. Job description\n",
    "3. System prompt\n",
    "4. LLM model (defaults to `\"gpt-4o-mini\"`)\n",
    "5. Temperature (defaults to `1.0`)\n",
    "\n",
    "It outputs a new résumé that is based on the base résumé, but fine-tuned to match the job description, in Markdown format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a326fa1-03e6-45a2-af9e-4ad296ab2777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_customized_resume(\n",
    "    reference_resume,\n",
    "    job_description,\n",
    "    system_prompt,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1.0\n",
    "):\n",
    "    return create_completion(\n",
    "        system_prompt,\n",
    "        create_resume_prompt(reference_resume, job_description),\n",
    "        model,\n",
    "        temperature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac559b9c",
   "metadata": {},
   "source": [
    "Now that we have the `generate_customized_resume()` function, let’s run it and store the result in a variable named `OPTIMIZED_RESUME`. Be patient when you run it; the process will typically take anywhere from 10 to 20 seconds, but can sometimes take longer.\n",
    "\n",
    "Once we have the generated résumé, we’ll write it to a file named `optimized_resume.md` in the `output` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33f133ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZED_RESUME = generate_customized_resume(\n",
    "    REFERENCE_RESUME, JOB_DESCRIPTION, SYSTEM_PROMPT\n",
    ")\n",
    "with open(f\"./output/optimized_resume.md\", \"w\") as f:\n",
    "    f.write(OPTIMIZED_RESUME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586ad8d2",
   "metadata": {},
   "source": [
    "## Cover letter\n",
    "\n",
    "### Create a function to define a user prompt for creating a cover letter\n",
    "Let’s define a function that returns a user prompt asking the LLM to create a cover letter, given the following information:\n",
    "\n",
    "- `resume`: The résumé on which the cover letter will be based. You could use the reference résumé, but it would be far better if you used the optimized one, since it’s what you’re going to provide with the cover letter.\n",
    "- `job_description`: The same job description you used for the résumé.\n",
    "- `company_name`: The name of the company to whom you’re sending the cover letter. The LLM will incorporate the company name into the cover letter.\n",
    "- `recipient_name`: Optional — if you know the recipient’s name, you can provide it, and the LLM will incorporate it into the cover letter.\n",
    "- `additional_context`: If there’s anything that the LLM should know about you, your experience, or your skills that you think should be mentioned in the cover letter, you can provide this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c829ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cover_letter_prompt(\n",
    "    resume, \n",
    "    job_description, \n",
    "    company_name, \n",
    "    recipient_name=\"Unknown\", \n",
    "    additional_context=\"\"\n",
    "):\n",
    "    return f\"\"\"\n",
    "        Context\n",
    "        -------\n",
    "        You are tasked with generating a highly personalized cover letter that connects a candidate's qualifications\n",
    "        to a specific job opportunity. Use the provided resume and job description to create a persuasive, professional\n",
    "        letter that positions the candidate as an ideal match.\n",
    "\n",
    "        Input Information\n",
    "        -----------------\n",
    "        Job Description:\n",
    "        {job_description}\n",
    "        \n",
    "        Resume:\n",
    "        {resume}\n",
    "        \n",
    "        - Company Name: {company_name}\n",
    "        - Recipient Name: {recipient_name}\n",
    "        - Additional Context: \n",
    "          {additional_context}\n",
    "        \n",
    "        Instructions\n",
    "        ------------\n",
    "        Create a tailored cover letter that:\n",
    "\n",
    "        - Opens with a compelling introduction that mentions the specific position and briefly explains the candidate's interest\n",
    "        - Identifies 2-3 key job requirements and directly connects them to specific experiences or skills from the resume\n",
    "        - Demonstrates understanding of the company's mission, values, or recent achievements (if provided)\n",
    "        - Explains why the candidate would be an excellent cultural fit based on their background and the company's environment\n",
    "        - Closes with enthusiasm for the opportunity and a clear call to action\n",
    "\n",
    "        Requirements\n",
    "        ------------\n",
    "        - Maintain a professional yet conversational tone appropriate for the industry and position level\n",
    "        - Be concise (350-450 words) and focused only on the most relevant qualifications\n",
    "        - Use concrete examples and metrics from the resume when applicable\n",
    "        - Avoid generic template language and empty flattery\n",
    "        - Structure with proper business letter formatting including date, addresses, greeting, and signature\n",
    "        - Match the candidate's experience level in language and tone (entry-level, mid-career, or executive)\n",
    "        - Emphasize transferable skills when direct experience is limited\n",
    "        - Include only truthful information present in the resume\n",
    "\n",
    "        Output Format\n",
    "        -------------\n",
    "        Return a properly formatted business letter in Markdown that includes:\n",
    "\n",
    "        - Current date\n",
    "        - Recipient's information (if provided)\n",
    "        - Professional greeting\n",
    "        - 3-4 well-structured paragraphs\n",
    "        - Professional closing\n",
    "        - Candidate's name as signature\n",
    "\n",
    "        The letter should read as if written by the candidate themselves, reflecting their genuine interest and qualifications.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1640c",
   "metadata": {},
   "source": [
    "### Create a function to generate a cover letter\n",
    "\n",
    "Now that we have a cover letter prompt function, let’s create a function to actually generate the cover letter. Just as `generate_customized_resume()` is a wrapper around the `create_completion()` function to generate a résumé, this function, `generate_cover_letter()`, is the cover letter version.\n",
    "\n",
    "It takes the following inputs:\n",
    "\n",
    "1. Résumé (preferably the fine-tuned one)\n",
    "2. Job description\n",
    "3. Company name\n",
    "4. Recipient name (defaults to `\"Unknown\"`)\n",
    "5. Additional context (defaults to `\"\"`)\n",
    "6. System prompt (defaults to `SYSTEM_PROMPT`)\n",
    "7. LLM model (defaults to `\"gpt-4o-mini\"`)\n",
    "8. Temperature (defaults to `1.0`)\n",
    "\n",
    "It outputs a cover letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d39e313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cover_letter(\n",
    "    resume,\n",
    "    job_description,\n",
    "    company_name,\n",
    "    recipient_name=\"Unknown\", \n",
    "    additional_context=\"\",\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=1.0\n",
    "):\n",
    "    return create_completion(\n",
    "        system_prompt,\n",
    "        create_cover_letter_prompt(resume, job_description, company_name, recipient_name, additional_context),\n",
    "        model,\n",
    "        temperature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303aa4d5",
   "metadata": {},
   "source": [
    "Let’s run the `generate_cover_letter()` function and store its result in a variable named `COVER_LETTER`. Just like with the optimized résumé, it will take about 10 - 20 seconds to generate the cover letter.\n",
    "\n",
    "Once the cover letter has been generated, we’ll write it to a file named `cover_letter.md` in the `output` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4179be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "COVER_LETTER = generate_cover_letter(\n",
    "    OPTIMIZED_RESUME, \n",
    "    JOB_DESCRIPTION, \n",
    "    \"Datadog\", \n",
    "    None,\n",
    "    \"I have 10+ years experience in Python programming.\")\n",
    "with open(f\"./output/cover_letter.md\", \"w\") as f:\n",
    "    f.write(COVER_LETTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e93287f",
   "metadata": {},
   "source": [
    "## Copy the documents to the clipboard\n",
    "\n",
    "If you’ve run every cell in this notebook up to this point, the application has the following text data in Markdown format:\n",
    "\n",
    "- The optimized résumé, which is stored in memory in the “constant” `OPTIMIZED_RESUME`\n",
    "- The cover letter, which lives in the “constant” `COVER_LETTER`\n",
    "\n",
    "You could immediately turn both of these into PDF files and submit them, but I don’t recommend that. You’ll want to review them first, and perhaps make some edits and fix some quirks that give away that your résumé and cover letter were generated.\n",
    "\n",
    "### Copy the optimized résumé to the clipboard\n",
    "The code cell below copies the optimized résumé to the clipboard. Run it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f3a80cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(OPTIMIZED_RESUME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b8fe2",
   "metadata": {},
   "source": [
    "...then paste the clipboard’s contents into an editor that will properly format Markdown text that you paste into it, such as Google Docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625c49c",
   "metadata": {},
   "source": [
    "### Copy the cover letter to the clipboard\n",
    "The code cell below copies the cover letter to the clipboard. As with the optimized résumé, run the cell below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055fb3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(COVER_LETTER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e13d3",
   "metadata": {},
   "source": [
    "...then paste the clipboard’s contents into Google Docs or any other editor that will properly format Markdown text that you paste into it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364c31e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
